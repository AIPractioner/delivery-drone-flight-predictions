{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1NxdpEQGHs7K"
      },
      "outputs": [],
      "source": [
        "!pip install tensorflow\n",
        "!pip install scikeras\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler, MinMaxScaler # Import MinMaxScaler here\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import LSTM, Dense # Import LSTM and Dense here\n",
        "from scikeras.wrappers import KerasClassifier, KerasRegressor\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.pipeline import Pipeline\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "\n",
        "optimizer = Adam(learning_rate=0.001)  # Set learning rate here\n",
        "model.compile(optimizer=optimizer, loss='mse')\n",
        "\n",
        "# Select relevant columns for the analysis\n",
        "data = drone_df_edited[['time', 'battery_current', 'battery_voltage', 'payload', 'altitude', 'speed', 'wind_speed', 'wind_angle']]\n",
        "\n",
        "# Define dependent (y) and independent (X) variables\n",
        "X = data[['payload', 'altitude', 'speed', 'wind_speed', 'wind_angle']]\n",
        "y = data[['battery_current', 'battery_voltage']]\n",
        "\n",
        "# Scale data using MinMaxScaler\n",
        "# Prefered for LSTM\n",
        "scaler_X = MinMaxScaler()\n",
        "scaler_y = MinMaxScaler()\n",
        "X = scaler_X.fit_transform(X)\n",
        "y = scaler_y.fit_transform(y)\n",
        "\n",
        "# Create a dataset with lookback\n",
        "# Should help predict battery current and voltage by remembering what happened previously\n",
        "def create_dataset(dataset, look_back=1):\n",
        "    X, Y = [], []\n",
        "    for i in range(len(dataset)-look_back-1):\n",
        "        a = dataset[i:(i+look_back), :-2] # Independent variables\n",
        "        X.append(a)\n",
        "         # Dependent variables (battery_current, battery_voltage)\n",
        "        Y.append(dataset[i + look_back, -2:])\n",
        "    return np.array(X), np.array(Y)\n",
        "\n",
        "# Number of previous steps to consider\n",
        "look_back = 10\n",
        "X, y = create_dataset(np.concatenate([X, y], axis=1), look_back)\n",
        "\n",
        "# Split data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Build the LSTM model\n",
        "model = Sequential()\n",
        "model.add(LSTM(units=100, return_sequences=True, input_shape=(X_train.shape[1], X_train.shape[2])))\n",
        "model.add(LSTM(units=100))\n",
        "# Output layer with 2 neurons (battery_current, battery_voltage)\n",
        "model.add(Dense(units=2))\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer='adam', loss='mse')\n",
        "\n",
        "# Train the model\n",
        "# model.fit(X_train, y_train, epochs=10, batch_size=32)\n",
        "\n",
        "# y_pred_10_epochs = model.predict(X_test)\n",
        "# y_pred_10_epochs = scaler_y.inverse_transform(y_pred_10_epochs)\n",
        "# mse_10_epochs = np.mean(np.square(y_test - y_pred_10_epochs))\n",
        "# print(f\"Mean Squared Error (10 epochs): {mse_10_epochs}\")\n",
        "\n",
        "\n",
        "# Train the model with 25 epochs and calculate new MSE\n",
        "# model.fit(X_train, y_train, epochs=25, batch_size=32) # Changed epochs to 25\n",
        "# y_pred_25_epochs = model.predict(X_test)\n",
        "# y_pred_25_epochs = scaler_y.inverse_transform(y_pred_25_epochs)\n",
        "# mse_25_epochs = np.mean(np.square(y_test - y_pred_25_epochs))\n",
        "# print(f\"Mean Squared Error (25 epochs): {mse_25_epochs}\")\n",
        "\n",
        "# Train the model with 50 epochs and model units = 100, change the optimizer\n",
        "model.fit(X_train, y_train, epochs=50, batch_size=32)\n",
        "y_pred_50_epochs = model.predict(X_test)\n",
        "y_pred_50_epochs = scaler_y.inverse_transform(y_pred_50_epochs)\n",
        "mse_50_epochs = np.mean(np.square(y_test - y_pred_50_epochs))\n",
        "print(f\"Mean Squared Error (50 epochs) and batch size = 32: {mse_50_epochs}\")"
      ]
    }
  ]
}